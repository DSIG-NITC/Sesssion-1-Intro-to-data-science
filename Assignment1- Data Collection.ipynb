{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Football!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIFA world cup** is the most widely viewed sporting event in the world having its latest 2018 Russian version attracted *3.5 billion* viewers. The matches were held between 14 June - 15 July. 32 teams competed in a total of 64 matches in 12 different stadiums. Deschamps' French team won the tournament thrashing Croatia **4-2** in the finals and *Modric* still bagging the *Golden Ball*\n",
    "\n",
    "**Fun fact**: *Global human population is estimated around 7.7 billion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From text to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to add the above **data** to _Python_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Cup\n"
     ]
    }
   ],
   "source": [
    "event_name = 'World Cup'\n",
    "\n",
    "print(event_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. String data - they go wrapped in quotes '' or \"\"\n",
    "host_organisation = 'FIFA'\n",
    "host_nation = 'Russia'\n",
    "winning_nation = 'France'\n",
    "\n",
    "# 2. Integer data \n",
    "version = 2018\n",
    "total_matches = 64\n",
    "total_venues = 12\n",
    "\n",
    "# 3. Float data - store decimal values\n",
    "total_viewers_billion = 3.5\n",
    "human_population_billion = 7.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:helvetica\">\n",
    "Manual collection of data like this gets tedious and boring easily. We'll look at how to automate the process to extract the required data\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# IMPORT NECESSARY PACKAGES\n",
    "###########################\n",
    "\n",
    "# highly optimised calculations on large arrays\n",
    "import numpy as np\n",
    "\n",
    "# collection of functions to manipulate data\n",
    "import pandas as pd\n",
    "\n",
    "# base library in Python for plotting graphs\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for better visualizations\n",
    "# import seaborn as sns\n",
    "\n",
    "# for plotting on maps\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# sending and receiving HTTP requests\n",
    "import requests\n",
    "\n",
    "# parsing html data \n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "\n",
    "# for easy searching and replacing using regular expression\n",
    "import re\n",
    "\n",
    "# better dictionary\n",
    "from collections import defaultdict \n",
    "\n",
    "# pretty print values\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Get sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Wikipedia article on [2018 FIFA World Cup](https://en.wikipedia.org/wiki/2018_FIFA_World_Cup) to get more data on the event\n",
    "\n",
    "> The *Art* of retrieving data from the web is **Web Scraping**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests returned a <class 'requests.models.Response'> object\n",
      "text is a <class 'str'> object\n"
     ]
    }
   ],
   "source": [
    "## Get the wikipedia page's html content using Python\n",
    "## Pointers - https://realpython.com/python-requests/  \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "\n",
    "# send an HTTP get request to the wikipiedia server for the required page\n",
    "html = requests.get('https://en.wikipedia.org/wiki/2018_FIFA_World_Cup')\n",
    "print(f\"requests returned a {type(html)} object\")\n",
    "\n",
    "# get string version of Response object returned by requests\n",
    "text = html.text\n",
    "print(f\"text is a {type(text)} object\")\n",
    "      \n",
    "# convert to a BeautifulSoup object for easy parsing\n",
    "soup = bsoup(text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pretty print contents of the webpage\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The window on far right has a quick overview - let's get that **DATA**\n",
    "\n",
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1XDoUcWBuiTwnBn_-cLvvuVXNI-N9SOTs\" alt=\"Wiki Home - 2018 Fifa WC\" width=\"720p\">\n",
    "</p>\n",
    "<p align=\"center\" style=\"text-align:center\"> Source: Wikipedia</p> \n",
    "\n",
    "Ok, we have the website and know where to *scrape* data from - How to do it?\n",
    "\n",
    "We'll analyze the website html. While you are at the wikipedia page, right-click on the window we need to collect data from  and select **Inspect**. The pop-up displays the HTML for the wikipedia page. \n",
    "\n",
    "\n",
    "<p align=\"center\" style=\"text-align:center\"> <b>Opening Developer Tools</b></p> \n",
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=105CHEVsaUtU2iRPYSXCcb8rCQuGrTNaV\" alt=\"Wiki Home - 2018 Fifa WC\" >\n",
    "</p>\n",
    "\n",
    "<p align=\"center\" style=\"text-align:center\"><b>Data Highlighted</b></p> \n",
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1Iak8Bf5yB1Ni6KKZAqcZ-z90A60FBpDB\" alt=\"Wiki Home - 2018 Fifa WC\" >\n",
    "</p>\n",
    "\n",
    "<p align=\"center\" style=\"text-align:center\"> Source: Wikipedia</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to identify the box somehow, we'll make use of the tags for this. When you hover over different tags in the developer window, the corresponding section of the webpage will light up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Fill the 'attrs' parameter of 'soup.find method with the class of the <table> tag \n",
    "# that completely wraps the information box\n",
    "infobox = soup.find('table', attrs={'class': 'infobox vcalendar'})\n",
    "\n",
    "# infobox = soup.find('table', attrs={'class': ''})\n",
    "\n",
    "# prints the content of the information box\n",
    "print(infobox.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1XDoUcWBuiTwnBn_-cLvvuVXNI-N9SOTs\" alt=\"Wiki-home\" width=\"720p\">\n",
    "</p>\n",
    "<p align=\"center\"> Source: Wikipedia</p> -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22 <tr> tags in the html of the infobox \n",
      "\n",
      "{'Attendance': '3,031,768 (47,371 per match)',\n",
      " 'Best goalkeeper': ' Thibaut Courtois',\n",
      " 'Best player(s)': ' Luka Modrić',\n",
      " 'Best young player': ' Kylian Mbappé',\n",
      " 'Champions': ' France (2nd title)',\n",
      " 'Dates': '14 June – 15 July',\n",
      " 'Fair play award': ' Spain',\n",
      " 'Fourth place': ' England',\n",
      " 'Goals scored': '169 (2.64 per match)',\n",
      " 'Host country': 'Russia',\n",
      " 'Matches played': '64',\n",
      " 'Runners-up': ' Croatia',\n",
      " 'Teams': '32 (from 5 confederations)',\n",
      " 'Third place': ' Belgium',\n",
      " 'Top scorer(s)': ' Harry Kane (6 goals)',\n",
      " 'Venue(s)': '12 (in 11 host cities)'}\n"
     ]
    }
   ],
   "source": [
    "# there are multiple <tr> tags in html of the infobox, \n",
    "# the attribute-value pairs have <th>&<td> in their <tr>s\n",
    "# Host country : Russia , Host country is the attribute & Russia its value\n",
    "\n",
    "# TODO 2: complete the call to the find_all method for returning all the <tr> tags\n",
    "infobox_rows = infobox.find_all('tr')\n",
    "# infobox_rows = infobox.find_all('')\n",
    "\n",
    "\n",
    "print(f\"There are {len(infobox_rows)} <tr> tags in the html of the infobox \\n\")\n",
    "\n",
    "# create a dictionary to store attribute-value pairs, or key-value if you prefer\n",
    "infobox_data = {}\n",
    "\n",
    "''' \n",
    " Sample <tr> tag:\n",
    " \n",
    " <tr>\n",
    "    <th scope=\"row\">\n",
    "        Host country\n",
    "    </th>\n",
    "    <td>\n",
    "        Russia\n",
    "    </td>\n",
    " </tr>\n",
    "  \n",
    "  \n",
    " checking the content of 'infobox' you can see that \n",
    " <tr> tags with data in it has both <th> and <td> tags as its children\n",
    " attribute name is in <th> and attribute value in <td>\n",
    "'''\n",
    "\n",
    "# TODO3: Loop through 'infobox_rows'\n",
    "# for row in ... :\n",
    "for row in infobox_rows:\n",
    "    # check if both <th> and <td> tags are present\n",
    "    if row.th is not None and row.td is not None:\n",
    "        # get text content from the tags\n",
    "        attribute = row.th.text\n",
    "        value = row.td.text\n",
    "        \n",
    "        # some encoding stuff\n",
    "        # https://stackoverflow.com/a/11566398/9734484\n",
    "        attribute = attribute.replace('\\xa0', ' ')\n",
    "        value = value.replace('\\xa0', ' ')\n",
    "        \n",
    "        # TODO4: add to 'infobox_data' the data\n",
    "        # use attribute as key and value as value to the dictionary\n",
    "#         infobox_data[...] = ...\n",
    "        infobox_data[attribute] = value\n",
    "    \n",
    "    \n",
    "pprint(infobox_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32 (from 5 confederations)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO 5: Print the value of the attribute 'Teams' from infobox_data\n",
    "# print(...)\n",
    "print(infobox_data['Teams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Host country\": \"Russia\",\n",
      "  \"Dates\": \"14 June \\u2013 15 July\",\n",
      "  \"Teams\": \"32 (from 5 confederations)\",\n",
      "  \"Venue(s)\": \"12 (in 11 host cities)\",\n",
      "  \"Champions\": \" France (2nd title)\",\n",
      "  \"Runners-up\": \" Croatia\",\n",
      "  \"Third place\": \" Belgium\",\n",
      "  \"Fourth place\": \" England\",\n",
      "  \"Matches played\": \"64\",\n",
      "  \"Goals scored\": \"169 (2.64 per match)\",\n",
      "  \"Attendance\": \"3,031,768 (47,371 per match)\",\n",
      "  \"Top scorer(s)\": \" Harry Kane (6 goals)\",\n",
      "  \"Best player(s)\": \" Luka Modri\\u0107\",\n",
      "  \"Best young player\": \" Kylian Mbapp\\u00e9\",\n",
      "  \"Best goalkeeper\": \" Thibaut Courtois\",\n",
      "  \"Fair play award\": \" Spain\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# json is a file format with a data representation similar to Python dicts\n",
    "# We'll save our infobox data into a json file on disk\n",
    "# https://realpython.com/python-json/\n",
    "import json\n",
    "\n",
    "# json.dumps - return Python string from JSON encoded data \n",
    "\n",
    "with open('data/infobox-data.json', 'w') as fp:\n",
    "    '''\n",
    "    json.dump(data, file_pointer) - save JSON encoded data into disk\n",
    "    \n",
    "    Input:\n",
    "        data - data to be stored\n",
    "        file_pointer - location to be stored\n",
    "        indent - indentation level to use\n",
    "    '''\n",
    "    json.dump(infobox_data, fp, indent=2)\n",
    "    \n",
    "del infobox_data\n",
    "\n",
    "\n",
    "# TODO 6: Fill arguments for the json.load() function call to load json data into infobox variable\n",
    "with open('data/infobox-data.json', 'r') as fp:\n",
    "    '''\n",
    "    # json.load(file_pointer) - load saved JSON encoded data from disk\n",
    "    \n",
    "    Input:\n",
    "        file_pointer - location to be read from\n",
    "    '''\n",
    "#     infobox_data  = json.load(...)\n",
    "    infobox_data  = json.load(fp)\n",
    "    \n",
    "    \n",
    "# TODO 7: save json data as a string with indentation 2\n",
    "# Fill arguments to json.dumps()\n",
    "# infobox_data_string = json.dumps(..., ...)\n",
    "infobox_data_string = json.dumps(infobox_data, indent=2)\n",
    "\n",
    "# print the contents\n",
    "print(infobox_data_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Teams by confederation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:helvetica\"> Let's get details of all teams that played the 2018 Fifa World Cup\n",
    "and the Confederation they represent</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1Uo2AnHRCDxPKDQivs_052lvBVHwaEPUx\" alt=\"Teams by confederation\" >\n",
    "</p>\n",
    "<p align=\"center\" style=\"text-align:center\"> Source: Wikipiedia </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# TODO 8: Find the class of the table that wraps the required data\n",
    "# multicol_tables = soup.find_all('table', attrs={'class':'...'})\n",
    "multicol_tables = soup.find_all('table', attrs={'class':'multicol'})\n",
    "\n",
    "# let's check if we got ourselves more than one table\n",
    "print(len(multicol_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9: Print out each of the three tables we found\n",
    "# Find the index of the tabel for our data\n",
    "# idx = ...\n",
    "idx = 0\n",
    "print(multicol_tables[idx].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the table\n",
    "teams_by_confederation_table = multicol_tables[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find confederation tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dl>\n",
      " <dt>\n",
      "  <a href=\"/wiki/2018_FIFA_World_Cup_qualification_(AFC)\" title=\"2018 FIFA World Cup qualification (AFC)\">\n",
      "   AFC\n",
      "  </a>\n",
      "  (5)\n",
      " </dt>\n",
      "</dl>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You can find all the confederation names are inside dl tags\n",
    "\n",
    "<dl>\n",
    "     <dt>\n",
    "          <a href=\"/wiki/2018_FIFA_World_Cup_qualification_(AFC)\" title=\"2018 FIFA World Cup qualification (AFC)\">\n",
    "           AFC\n",
    "          </a>\n",
    "          (5)\n",
    "     </dt>\n",
    "</dl\n",
    "''' \n",
    "\n",
    "# TODO 10: Use appropriate function to 'find all' <dl> tags in teams_by_confideration_table\n",
    "# confederation_tags = ...\n",
    "confederation_tags = teams_by_confederation_table.find_all('dl')\n",
    "\n",
    "print(confederation_tags[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFC (5)\n"
     ]
    }
   ],
   "source": [
    "# print only the text inside the html \n",
    "print(confederation_tags[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFC (5)\n",
      "CAF (5)\n",
      "CONCACAF (3)\n",
      "CONMEBOL (5)\n",
      "OFC (0)\n",
      "UEFA (14)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO 11: \n",
    "1. Loop through the confederation_tags list\n",
    "2. print text in each confederation tag\n",
    "\n",
    "Example output - \n",
    "\n",
    "AFC (5)\n",
    "CAF (5)\n",
    "CONCACAF (3)\n",
    "CONMEBOL (5)\n",
    "OFC (0)\n",
    "UEFA (14)\n",
    "\n",
    "'''\n",
    "\n",
    "# for tag in ...:\n",
    "#     print(...)\n",
    "    \n",
    "for tag in confederation_tags:\n",
    "    print(tag.text)\n",
    "    \n",
    "# TODO(Optional): Print the text in the tags using list comprehension\n",
    "# print([tag.text for tag in confederation_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean confederation names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFC\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "'''\n",
    "Remove from 'confederation_tags' extra details in the text data part from the Country name\n",
    "\n",
    "Input: AFC (5)\n",
    "Output: AFC\n",
    "'''\n",
    "\n",
    "confederation_text = \"AFC (5)\"\n",
    "\n",
    "\n",
    "def clean_confederation_text(text):\n",
    "    # TODO 12: Use appropriate string operation to SPLIT the name and the other info to list of two strings\n",
    "    # Input: \"AFC (5)\"\"\n",
    "    # Output: [\"AFC\", \"(5)\"]\n",
    "\n",
    "    # confederation_split = ...\n",
    "    confederation_split = text.split(\" \")\n",
    "\n",
    "\n",
    "    # TODO 13: Get the text string from the list\n",
    "    # confederation_cleaned = ...\n",
    "    confederation_cleaned = confederation_split[0]\n",
    "\n",
    "    return confederation_cleaned\n",
    "\n",
    "\n",
    "confederation_cleaned = clean_confederation_text(confederation_text)\n",
    "\n",
    "print(confederation_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFC', 'CAF', 'CONCACAF', 'CONMEBOL', 'OFC', 'UEFA']\n"
     ]
    }
   ],
   "source": [
    "# TODO 14: Loop through all the confederation tags and save only the name part\n",
    "# You have to give as argument to the clean_confederation_text function the TEXT in tags\n",
    "\n",
    "# confederations = [clean_confederation_text(...) for tag in confederation_tags]\n",
    "confederations = [clean_confederation_text(tag.text) for tag in confederation_tags]\n",
    "\n",
    "print(confederations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find list of teams in each confederation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Australia (36)\n",
      " Iran (37)\n",
      " Japan (61)\n",
      " Saudi Arabia (67)\n",
      " South Korea (57)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Info on teams in each confederation is in <ul> tag directly following\n",
    "the <dl> tag of the corresponding confederation\n",
    "\n",
    "TODO 15: Use appropriate function to 'find all' <ul> tags in teams_by_confideration_table\n",
    "'''\n",
    "\n",
    "# teams_list_tags = ...\n",
    "teams_list_tags = teams_by_confederation_table.find_all('ul')\n",
    "\n",
    "# print text in one of the teams list tag\n",
    "print(teams_list_tags[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/wiki/Australia_national_soccer_team\" title=\"Australia national soccer team\">Australia</a>,\n",
      " <a href=\"/wiki/Iran_national_football_team\" title=\"Iran national football team\">Iran</a>,\n",
      " <a href=\"/wiki/Japan_national_football_team\" title=\"Japan national football team\">Japan</a>,\n",
      " <a href=\"/wiki/Saudi_Arabia_national_football_team\" title=\"Saudi Arabia national football team\">Saudi Arabia</a>,\n",
      " <a href=\"/wiki/South_Korea_national_football_team\" title=\"South Korea national football team\">South Korea</a>]\n"
     ]
    }
   ],
   "source": [
    "# Now we have a list with all teams in a confederation as a single entity\n",
    "# Let's split that too\n",
    "\n",
    "afc_teams_tag = teams_list_tags[0]\n",
    "\n",
    "# On inspection you can see that all the <a> tag of each team name has as text the corresponding team name\n",
    "# eg: <a href=\"/wiki/Australia_national_soccer_team\" title=\"Australia national soccer team\">Australia</a>\n",
    "\n",
    "#TODO 16: Find all <a> tags within a <ul> tag - afc_teams\n",
    "afc_teams_a_tags = afc_teams_tag.find_all('a')\n",
    "\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "[<a href=\"/wiki/Australia_national_soccer_team\" title=\"Australia national soccer team\">Australia</a>,\n",
    "<a href=\"/wiki/Iran_national_football_team\" title=\"Iran national football team\">Iran</a>,\n",
    "<a href=\"/wiki/Japan_national_football_team\" title=\"Japan national football team\">Japan</a>, \n",
    "<a href=\"/wiki/Saudi_Arabia_national_football_team\" title=\"Saudi Arabia national football team\">Saudi Arabia</a>, \n",
    "<a href=\"/wiki/South_Korea_national_football_team\" title=\"South Korea national football team\">South Korea</a>]\n",
    "'''\n",
    "\n",
    "pprint(afc_teams_a_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australia', 'Iran', 'Japan', 'Saudi Arabia', 'South Korea']\n"
     ]
    }
   ],
   "source": [
    "print([team_a_tag.text for team_a_tag in afc_teams_a_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confederation list has 6 items\n",
      "Teams list has 6 items, each having all the teams in a confederation\n"
     ]
    }
   ],
   "source": [
    "# def get_list_of_team_names_from_conf_tags(tags):\n",
    "#     teams_a_tag = tags.find_all('a')\n",
    "    \n",
    "#     team_names = [team_a_tag.text for team_a_tag in teams_a_tag]\n",
    "    \n",
    "#     return team_names\n",
    "\n",
    "\n",
    "# afc_teams = get_list_of_team_names_from_conf_tags(afc_teams_tag)\n",
    "# print(afc_teams)\n",
    "print(f'Confederation list has {len(confederations)} items')\n",
    "print(f'Teams list has {len(teams_list_tags)} items, each having all the teams in a confederation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So, first confederation in `confederations` will correspond to the first team names tag in `teams_list_tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store teams by confederation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Belgium', 'Croatia', 'Denmark', 'England', 'France', 'Germany', 'Iceland', 'Poland', 'Portugal', 'Russia', 'Serbia', 'Spain', 'Sweden', 'Switzerland']\n"
     ]
    }
   ],
   "source": [
    "# Now we will add all the teams to their corresponding confs and use a dict to save it\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# TODO 17: Create a dictionary with values pre-initialized as list\n",
    "# Pointer - https://docs.python.org/3.3/library/collections.html#collections.defaultdict\n",
    "# teams_by_confederation = defaultdict(...)\n",
    "teams_by_confederation = defaultdict(list)\n",
    "\n",
    "\n",
    "\n",
    "for i, confederation in enumerate(confederations):\n",
    "    # find the teams tag corresponding to the confederation\n",
    "    confederation_teams_tag = teams_list_tags[i]\n",
    "    \n",
    "    # TODO 18: ind all <a> tags in 'confederation_teams_tag'\n",
    "    # for anchor in ...:\n",
    "    for anchor in confederation_teams_tag.find_all('a'):\n",
    "        \n",
    "        # TODO 19: extract only text from the anchor tag\n",
    "        # Example\n",
    "        # Input: <a href=\"/wiki/Australia_national_soccer_team\" title=\"Australia national soccer team\">Australia</a>\n",
    "        # Output: Australia\n",
    "        # team = ...\n",
    "        team_name = anchor.text\n",
    "        \n",
    "        # TODO 20: Append the team name to the corresponding confederation key in 'teams_by_confederation'\n",
    "        # teams_by_confederation[...].append(team_name)\n",
    "        teams_by_confederation[confederation].append(team_name)\n",
    "\n",
    "\n",
    "'''\n",
    "Output: ['Belgium', 'Croatia', 'Denmark', 'England', 'France', 'Germany', 'Iceland', 'Poland', 'Portugal', \n",
    "        'Russia', 'Serbia', 'Spain', 'Sweden', 'Switzerland']\n",
    "'''\n",
    "print(teams_by_confederation['UEFA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 21: Save the teams_by_confederation dictionary as a NEW JSON file called 'teams-by-confederation.json'\n",
    "\n",
    "# with open(... , ...) as fp:\n",
    "#     json.dump(..., ..., indent=2)\n",
    "    \n",
    "with open('data/teams-by-confederation.json', 'w') as fp:\n",
    "    json.dump(teams_by_confederation, fp, indent=2)\n",
    "    \n",
    "    \n",
    "# Open the 'teams-by-confederation.json' file to see its content, play with the indent parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Stadiums and capacity(Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1UM3qMIQhalJ3Z0RsMOIO5mpVLWeKkRe_\" alt=\"Stadiums and Capacity\">\n",
    "</p>\n",
    "<p align=\"center\" style=\"text-align:center\"> Source: Wikipedia </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Find all the tables having same class as the required table\n",
    "# 2. Inspect each of the returned tables to find the index of the required table\n",
    "# wikitables = soup.find_all(..., attrs=...)\n",
    "\n",
    "wikitables = soup.find_all('table', attrs={'class': 'wikitable'})\n",
    "\n",
    "# i = 0\n",
    "i = 3\n",
    "stadiums_table = wikitables[i]\n",
    "stadiums_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stadiums list contains \n",
      " ['Luzhniki Stadium', 'Otkritie Arena', 'Krestovsky Stadium', 'Fisht Olympic Stadium', 'Volgograd Arena', 'Rostov Arena', 'Nizhny Novgorod Stadium', 'Kazan Arena', 'Samara Arena', 'Mordovia Arena', 'Kaliningrad Stadium', 'Central Stadium'] \n",
      "\n",
      "Capacities list contains \n",
      " ['78,011', '44,190', '64,468', '44,287', '43,713', '43,472', '43,319', '42,873', '41,970', '41,685', '33,973', '33,061'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stadium names are inside anchor tag within td tags compared to regions which are in th tags\n",
    "stadium_and_capacity_tags = stadiums_table.find_all('td')\n",
    "\n",
    "# stadium tags are td with <a> having title\n",
    "# capacity tags are td with <b> and td.text having 'Capacity'\n",
    "# there are images also in td tags but their <a> has class \"image\"\n",
    "stadiums = []\n",
    "capacities = []\n",
    "\n",
    "for tag in stadium_and_capacity_tags:\n",
    "    # TODO: check for the string 'Capacity' in the tag's text\n",
    "    # if ... in ...:\n",
    "    if 'Capacity' in tag.text:\n",
    "        capacities.append(tag.b.text)\n",
    "        \n",
    "        \n",
    "    # TODO: check if class attribute of <a> tag is image\n",
    "    # if not, it will be stadium name, add the stadium NAME to the 'stadiums' list\n",
    "    # elif not tag.a.get(...) == ['image']:\n",
    "    elif not tag.a.get('class') == ['image']:\n",
    "        # stadiums.append(...)\n",
    "        stadiums.append(tag.a.text)\n",
    "        \n",
    "assert len(stadiums) == len(capacities)\n",
    "\n",
    "\n",
    "print(f\"Stadiums list contains \\n {stadiums} \\n\")\n",
    "print(f\"Capacities list contains \\n {capacities} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Central Stadium': '33,061',\n",
      " 'Fisht Olympic Stadium': '44,287',\n",
      " 'Kaliningrad Stadium': '33,973',\n",
      " 'Kazan Arena': '42,873',\n",
      " 'Krestovsky Stadium': '64,468',\n",
      " 'Luzhniki Stadium': '78,011',\n",
      " 'Mordovia Arena': '41,685',\n",
      " 'Nizhny Novgorod Stadium': '43,319',\n",
      " 'Otkritie Arena': '44,190',\n",
      " 'Rostov Arena': '43,472',\n",
      " 'Samara Arena': '41,970',\n",
      " 'Volgograd Arena': '43,713'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: store in a dictionary stadiums as key and their capacity as values\n",
    "\n",
    "stadiums_and_capacities = {stadium: capacity for stadium, capacity in zip(stadiums, capacities)}\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "{'Luzhniki Stadium': '78,011',\n",
    " 'Otkritie Arena': '44,190',\n",
    " 'Krestovsky Stadium': '64,468',\n",
    " 'Fisht Olympic Stadium': '44,287',\n",
    " 'Volgograd Arena': '43,713',\n",
    " 'Rostov Arena': '43,472',\n",
    " 'Nizhny Novgorod Stadium': '43,319',\n",
    " 'Kazan Arena': '42,873',\n",
    " 'Samara Arena': '41,970',\n",
    " 'Mordovia Arena': '41,685',\n",
    " 'Kaliningrad Stadium': '33,973',\n",
    " 'Central Stadium': '33,061'}\n",
    " \n",
    "'''\n",
    "pprint(stadiums_and_capacities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Group stage results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1p1Lwd9zR1uh7-vAyZj-37qeuYaqS4nwh\" alt=\"Group Stage Table\" >\n",
    "</p>\n",
    "<p align=\"center\" style=\"text-align:center\"> Source: Wikipedia </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "# Let's get all tables with a class of 'wikitable' and find which all we need\n",
    "\n",
    "wikitables = soup.find_all('table', attrs={'class': 'wikitable'})\n",
    "\n",
    "print(len(wikitables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:helvetica\">\n",
    "We got 19 tables to filter 8 corresponding to each Group\n",
    "\n",
    "> Quick question: **How many ways can you select 8 tables from 19?**\n",
    "\n",
    "\n",
    "And by the way, the above question is *COMPLETELY UNRELATED* to our purpose. Sorry, if you went on to calculate factorials :)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9, 10, 11, 17]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of our tables has a 'Pos' column\n",
    "# Let's filter the tables by this information\n",
    "\n",
    "[i for i, wikitable in enumerate(wikitables) if 'Pos' in wikitable.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:helvetica\">\n",
    "So, we have a total of 9 tables and tables 4-11 are 8 consecutive one. It's most likely those are what we need. \n",
    "\n",
    "Nb: \n",
    "<b> Skeptics are welcome to print the contents of Table 17 to ascertain above hypothesis</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you remember what was the last TODO number?\n",
    "# Yeah, that's what I thought. Let's scroll up!\n",
    "\n",
    "\n",
    "\n",
    "# TODO 22: select EIGHT tables 4 to 11\n",
    "# all_group_table_tags = ...\n",
    "all_group_table_tags = wikitables[4:12]\n",
    "\n",
    "assert len(all_group_table_tags) == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect contents of Group A table to get a hang of its structure\n",
    "groupA = all_group_table_tags[0]\n",
    "\n",
    "print(groupA.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you check the contents of groupA, each of the table row is a <tr> tag\n",
    "\n",
    "# TODO 23: find all <tr> tags in groupA\n",
    "groupA_table_rows = groupA.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first row is the attribute titles - we dont need 'Qualification'\n",
    "# all the cols except Team has the attribute names in th > abbr.title\n",
    "first_row = groupA_table_rows[0]\n",
    "\n",
    "print(first_row.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Position\">Pos</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"180\">Team<div class=\"plainlinks hlist navbar mini\" style=\"float:right\"><span style=\"margin-right:-0.125em\">[ </span><ul><li class=\"nv-view\"><a href=\"/wiki/Template:2018_FIFA_World_Cup_Group_A_table\" title=\"Template:2018 FIFA World Cup Group A table\"><abbr title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:2018_FIFA_World_Cup_Group_A_table\" title=\"Template talk:2018 FIFA World Cup Group A table\"><abbr title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Template:2018_FIFA_World_Cup_Group_A_table&amp;action=edit\"><abbr title=\"Edit this template\">e</abbr></a></li></ul><span style=\"margin-left:-0.125em\"> ]</span></div>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Played\">Pld</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Won\">W</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Drawn\">D</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Lost\">L</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Goals for\">GF</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Goals against\">GA</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Goal difference\">GD</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\" width=\"28\"><abbr title=\"Points\">Pts</abbr>\n",
      "</th>,\n",
      " '\\n',\n",
      " <th scope=\"col\">Qualification\n",
      "</th>]\n"
     ]
    }
   ],
   "source": [
    "pprint(first_row.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-363-819e40fa919d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# let's print the text of each first_row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfirst_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \"\"\"Find all parents of this PageElement that match the given criteria.\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mAll\u001b[0m \u001b[0mfind_\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mtake\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mset\u001b[0m \u001b[0mof\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0monline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mdocumentation\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetailed\u001b[0m \u001b[0mexplanations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# let's print the text of each first_row tags\n",
    "for col in first_row.contents:\n",
    "    print(col.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'bs4.element.NavigableString'> \n",
      "\n",
      "\n",
      " <class 'bs4.element.NavigableString'>\n",
      "<th scope=\"col\" width=\"28\"><abbr title=\"Position\">Pos</abbr>\n",
      "</th> <class 'bs4.element.Tag'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the type of the last 'col' which errored\n",
    "print(col, type(col), '\\n')\n",
    "\n",
    "print(first_row.contents[0], type(first_row.contents[0]))\n",
    "\n",
    "print(first_row.contents[1], type(first_row.contents[1]))\n",
    "\n",
    "first_row.contents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **\\n** string is a `bs4.element.NavigableString` object and is causing errors. We don't need that anyway, throw it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos\n",
      "Team\n",
      "Pld\n",
      "W\n",
      "D\n",
      "L\n",
      "GF\n",
      "GA\n",
      "GD\n",
      "Pts\n",
      "Qualification\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO 24: store rows that are not '\\n's\n",
    "# first_row_cleaned = [content for content in first_row if content != ...]\n",
    "first_row_cleaned = [content for content in first_row if content != '\\n']\n",
    "\n",
    "        \n",
    "for col in first_row_cleaned:\n",
    "    print(col.find(text=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<th scope=\"col\" width=\"28\"><abbr title=\"Position\">Pos</abbr>\n",
      "</th>\n",
      "Position\n"
     ]
    }
   ],
   "source": [
    "# The titles except 'Team' and 'Qualification' are all 'title' attribute of <abbr> tag \n",
    "print(first_row_cleaned[0])\n",
    "print(first_row_cleaned[0].find('abbr').get('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "# TODO 25: Loop through tags in first_row_cleaned\n",
    "# for row in ...:\n",
    "for row in first_row_cleaned:\n",
    "\n",
    "    # TODO 26: check for <abbr> tag\n",
    "    # recursive=False - return tag only if its the direct children\n",
    "    # if row.find(..., recursive=False):\n",
    "    if row.find('abbr', recursive=False):\n",
    "        titles.append(row.abbr.get('title'))\n",
    "    else:\n",
    "        # for 'Team' and 'Qualification' columns\n",
    "        titles.append(row.find(text=True).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Position', 'Team', 'Played', 'Won', 'Drawn', 'Lost', 'Goals for', 'Goals against', 'Goal difference', 'Points', 'Qualification']\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Position', 'Team', 'Played', 'Won', 'Drawn', 'Lost', 'Goals for', 'Goals against', 'Goal difference', 'Points']\n"
     ]
    }
   ],
   "source": [
    "titles = titles[:-1]\n",
    "\n",
    "print(len(titles), titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row is the table headers and the rest has team info\n",
    "\n",
    "team_rows = groupA_table_rows[1:]\n",
    "len(team_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<th scope=\"row\" style=\"text-align: center;font-weight: normal;background-color:#BBF3BB;\">1\n",
      "</th>,\n",
      " <td style=\"text-align: left; white-space:nowrap;font-weight: normal;background-color:#BBF3BB;\"><span style=\"white-space:nowrap\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"630\" data-file-width=\"945\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Flag_of_Uruguay.svg/23px-Flag_of_Uruguay.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Flag_of_Uruguay.svg/35px-Flag_of_Uruguay.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Flag_of_Uruguay.svg/45px-Flag_of_Uruguay.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Uruguay_national_football_team\" title=\"Uruguay national football team\">Uruguay</a></span>\n",
      "</td>,\n",
      " <td style=\"font-weight: normal;background-color:#BBF3BB;\">3\n",
      "</td>,\n",
      " <td style=\"font-weight: normal;background-color:#BBF3BB;\">3\n",
      "</td>,\n",
      " <td style=\"font-weight: normal;background-color:#BBF3BB;\">0\n",
      "</td>,\n",
      " <td style=\"font-weight: normal;background-color:#BBF3BB;\">0\n",
      "</td>,\n",
      " <td style=\"font-weight: normal;background-color:#BBF3BB;\">5\n",
      "</td>,\n",
      " <td style=\"font-weight: normal;background-color:#BBF3BB;\">0\n",
      "</td>,\n",
      " <td style=\"font-weight: normal;background-color:#BBF3BB;\">+5\n",
      "</td>,\n",
      " <td style=\"font-weight: bold;background-color:#BBF3BB;\">9\n",
      "</td>,\n",
      " <td rowspan=\"2\" style=\"font-weight: normal;background-color:#BBF3BB;\">Advance to <a href=\"/wiki/2018_FIFA_World_Cup#Knockout_stage\" title=\"2018 FIFA World Cup\">knockout stage</a>\n",
      "</td>]\n"
     ]
    }
   ],
   "source": [
    "# get first team\n",
    "team_row = team_rows[0]\n",
    "\n",
    "# remove NavigableStrings - '\\n'\n",
    "team_row_cleaned = [content for content in team_row if content!='\\n']\n",
    "\n",
    "pprint(team_row_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Uruguay', '3', '3', '0', '0', '5', '0', '+5', '9']\n"
     ]
    }
   ],
   "source": [
    "teams_data = []\n",
    "\n",
    "# get the row data \n",
    "team_data = [col.get_text(strip=True) for col in team_row_cleaned][:-1]\n",
    "\n",
    "print(team_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_table_headers(header_row):\n",
    "    '''\n",
    "    Returns list of table headers\n",
    "    \n",
    "    Input: Tag corresponding to first row of a group data table\n",
    "    Output: List of table headers\n",
    "        ['Position', 'Team', 'Played', 'Won', 'Drawn', 'Lost', 'Goals for', 'Goals against', \n",
    "        'Goal difference', 'Points']\n",
    "    '''\n",
    "    header_row_cleaned = [col for col in header_row.contents if col!='\\n']\n",
    "    \n",
    "    titles = []\n",
    "    # TODO(optional): Find out difference b/w .text vs get_text() vs find(text=True)\n",
    "    for row in header_row_cleaned:\n",
    "        if row.find('abbr', recursive=False):\n",
    "            titles.append(row.abbr.get('title'))\n",
    "        else:\n",
    "            titles.append(row.find(text=True))\n",
    "\n",
    "    # remove qualification header\n",
    "    titles = titles[:-1]\n",
    "    \n",
    "    return titles\n",
    "\n",
    "\n",
    "def get_group_team_data(team_row, num_headers):\n",
    "    '''\n",
    "    Returns list of column values given data row tag in group data table\n",
    "    \n",
    "    Input: \n",
    "        team_row - Tag corresponding to a team in group data table\n",
    "        num_headers - Number of headers present\n",
    "    \n",
    "    Output: List of data related to that team in the group\n",
    "        ['1', 'Uruguay', '3', '3', '0', '0', '5', '0', '+5', '9']\n",
    "    '''\n",
    "    \n",
    "    team_data = [col.get_text(strip=True) for col in team_row.contents if col!='\\n']\n",
    "    \n",
    "    # remove value of Qualification column if present\n",
    "    if len(team_data) == (num_headers + 1):\n",
    "        team_data = team_data[:-1]\n",
    "    \n",
    "    return team_data\n",
    "\n",
    "\n",
    "\n",
    "def get_group_teams_data(group_table, num_headers):\n",
    "    '''\n",
    "    Returns data of all teams in a group table\n",
    "    \n",
    "    Input: \n",
    "        group_table - tags corresponding to each row in the group table except first - header\n",
    "        num_headers - Number of headers present\n",
    "    \n",
    "    Output: List of data related to all teams in the group\n",
    "    '''\n",
    "    \n",
    "    teams_data = []\n",
    "    for team_row in group_table:\n",
    "        # get data of a single team\n",
    "        team_data = get_group_team_data(team_row, num_headers)\n",
    "        \n",
    "        # check no of cols\n",
    "        assert len(team_data) == num_headers\n",
    "        \n",
    "        # add team data to the teams data list\n",
    "        teams_data.append(team_data)\n",
    "    \n",
    "    \n",
    "    return teams_data\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def get_group_table_data(table_tag):\n",
    "    '''\n",
    "    Returns table data with headers\n",
    "    \n",
    "    Input: \n",
    "        table_tags - tag correspnding to a group table\n",
    "    \n",
    "    Output: full table data formatted\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    table_rows = table_tag.find_all('tr')\n",
    "    \n",
    "    header_row = table_rows[0]\n",
    "    team_rows = table_rows[1:]\n",
    "    \n",
    "    header_data = get_group_table_headers(header_row)\n",
    "    \n",
    "    num_headers = len(header_data)\n",
    "    \n",
    "    teams_data = get_group_teams_data(team_rows, num_headers)\n",
    "    \n",
    "    # TODO(optional): add header and team data to single list\n",
    "#     print(team_rows)\n",
    "    table_data = [header_data] + teams_data\n",
    "    assert len(table_data) == 5\n",
    "    assert table_data[0] == header_data\n",
    "    assert table_data[1:] == teams_data\n",
    "    \n",
    "    return table_data\n",
    "\n",
    "\n",
    "def get_group_tables_data(all_table_tags):\n",
    "    '''\n",
    "    Returns all of the tables' data\n",
    "    \n",
    "    Input: \n",
    "        all_table_tags - list of tags corresponding to each group table\n",
    "    \n",
    "    Output: List of data related to all teams in the group\n",
    "    '''\n",
    "    \n",
    "    group_tables = [get_group_table_data(table_tags) for table_tags in all_table_tags]\n",
    "    \n",
    "    return group_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'Uruguay', '3', '3', '0', '0', '5', '0', '+5', '9']"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first row returned by get_group_table_data on the first table\n",
    "(get_group_table_data(all_group_table_tags[0])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5, 10)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create a numpy array for storing all the group tables\n",
    "all_group_tables = np.array(get_group_tables_data(all_group_table_tags))\n",
    "all_group_tables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:helvetica\">\n",
    "    <ul>\n",
    "        <li>The <code>all_group_tables</code> numpy array contains each of the <b><i>8</i></b> groups data.</li>\n",
    "        <li>Each of the group has <b><i>5</i></b> rows in its table - One header row and 4 team rows.</li>\n",
    "        <li>Each row in the table has <b><i>10</i></b> attributes like Position, Team, Played etc</li>\n",
    "     </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    }
   ],
   "source": [
    "group_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "\n",
    "print(group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'A' 'A' 'A' 'B' 'B' 'B' 'B' 'C' 'C' 'C' 'C' 'D' 'D' 'D' 'D' 'E' 'E'\n",
      " 'E' 'E' 'F' 'F' 'F' 'F' 'G' 'G' 'G' 'G' 'H' 'H' 'H' 'H']\n"
     ]
    }
   ],
   "source": [
    "# TODO(optional): find difference b/w repeat and tile\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html\n",
    "\n",
    "repeat_group_names = np.repeat(group_names, 4)\n",
    "print(repeat_group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_group_tables(all_group_tables, group_names, num_teams_in_group=4):\n",
    "        '''\n",
    "        Combines all the group tables to a single elongated list\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        assert type(all_group_tables) == np.ndarray\n",
    "        assert len(all_group_tables) == len(group_names)\n",
    "        \n",
    "        # save headers\n",
    "        headers = all_group_tables[0][0]\n",
    "\n",
    "        '''\n",
    "        all_group_tables[:, :, :] - returns all the data in all_group_tables\n",
    "        \n",
    "        all_group_tables[0, :, :] - returns all data of the first group \n",
    "        all_group_tables[0, :, :].shape == (5, 10)\n",
    "        \n",
    "        all_group_tables[:, 0, :] - returns first row data(header) from each table\n",
    "        all_group_tables[:, 0, :].shape == (8, 1, 10)\n",
    "        \n",
    "        all_group_tables[:, 1:, :] - returns all row data except the first row(header) in each table\n",
    "        all_group_tables[:, 1:, :].shape == (8, 4, 10)\n",
    "        '''\n",
    "        # remove header from all groups\n",
    "        all_group_tables_no_header = all_group_tables[:, 1:, :]\n",
    "        \n",
    "        # all_group_tables_no_header == (8, 4, 10)\n",
    "        assert all_group_tables_no_header.shape[1] == num_teams_in_group        \n",
    "        \n",
    "        # TODO(optional): reshape all_group_tables_no_header to (32, 10)\n",
    "        # create a single table of all groups\n",
    "        all_group_single_table = all_group_tables_no_header.reshape(-1, len(headers))\n",
    "        \n",
    "        # TODO(optional): repeat group names\n",
    "        # add group name to all tables\n",
    "        \n",
    "        \n",
    "        group_names_repeated = np.repeat(group_names, num_teams_in_group)\n",
    "        \n",
    "        ### Add group_name as last col of each row\n",
    "        \n",
    "        # current last row index - all_group_tables_no_heder.shape[2] - 1\n",
    "        # because indexing starts at 0\n",
    "        col_index_to_insert = all_group_tables_no_header.shape[2]\n",
    "        \n",
    "        # Insert group names at the set index across columns(axis=1)\n",
    "        # https://docs.scipy.org/doc/numpy/reference/generated/numpy.insert.html\n",
    "        table_with_group_names = np.insert(all_group_single_table, col_index_to_insert\n",
    "                                                      , group_names_repeated, axis=1)\n",
    "        \n",
    "        # add Group to header list\n",
    "        # reshape headers to (1, 11) instead of (11,) to avoid future problems\n",
    "        headers = np.append(headers, 'Group').reshape(1, -1)\n",
    "        \n",
    "        # Concatenate headers and table data across rows(axis=0)\n",
    "        group_table_with_header = np.append(headers, table_with_group_names, axis=0)\n",
    "        \n",
    "        return group_table_with_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 11)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a single cumulated table with a header row and data of 32 teams in the group stage\n",
    "group_stage_results = combine_group_tables(all_group_tables, group_names)\n",
    "group_stage_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as a csv file\n",
    "with open('data/group_stage_results.csv', 'w', encoding=\"utf-8\") as fp:\n",
    "    for row in group_stage_results:\n",
    "        join_row_to_string = ','.join(row) + '\\n'\n",
    "        fp.write(join_row_to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:30px;font-family:Arial;text-align:center\">\n",
    "    <i>Congratulations on completing the First part of the Assignment</i>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=16zQgxLkXPK-IRCAZu9ZV271voD5kI576\" alt=\"Congrats\">\n",
    "</p>\n",
    "<p align=\"center\" style=\"text-align:center\"> Source: media.tenor.com </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;font-family:cursive\">\n",
    "    Don't forget to STRETCH b4 you move on to the <b>Data Analysis</b> section\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"text-align:center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=17lciATYFeJfoENoKR_alSAf1G_pzBWSg\" alt=\"CNN\" width=\"720p\">\n",
    "</p>\n",
    "<p align=\"center\" style=\"text-align:center\"> Source: media.tenor.com </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
